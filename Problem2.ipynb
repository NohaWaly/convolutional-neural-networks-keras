{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NohaWaly/convolutional-neural-networks-keras/blob/master/Problem2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ_Hn5ouIBY-",
        "colab_type": "code",
        "outputId": "6a9079c5-478a-4772-d8ea-1f7b10a8b22e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/ardamavi/Sign-Language-Digits-Dataset.git"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Sign-Language-Digits-Dataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYwIfoP1JKtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#cv2 to read image, show and more\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from keras import layers\n",
        "from keras import models as ml\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from numpy import argmax\n",
        "\n",
        "DataDir = \"Sign-Language-Digits-Dataset/Dataset\"\n",
        "ImgSize = 100\n",
        "\n",
        "Categories = [\"0\", \"1\",\"2\",\"3\", \"4\",\"5\",\"6\", \"7\",\"8\",\"9\"]\n",
        "data = []\n",
        "#iterate over 10 folders\n",
        "for category in Categories:  \n",
        "    # create path to each gesture \n",
        "    path = os.path.join(DataDir,category) \n",
        "    classNum = Categories.index(category)\n",
        "    #print(path)\n",
        "    # iterate over each image per each gesture \n",
        "    for img in os.listdir(path): \n",
        "        print(img)\n",
        "        # convert to array\n",
        "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_COLOR) \n",
        "        # resize data\n",
        "        resize_array = cv2.resize(img_array, (ImgSize, ImgSize))\n",
        "        #append to data\n",
        "        data.append([resize_array, classNum])\n",
        "        # graph it\n",
        "        #plt.imshow(img_array)\n",
        "        # display!   \n",
        "        #plt.show()  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEDs3HfzE4Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shuffle data (msh kol class ykon wara b3d)\n",
        "random.shuffle(data)  \n",
        "#print(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qKzRyF7E_XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in data:\n",
        "   X.append(features)\n",
        "   y.append(label)\n",
        "#to enter the model it should be np array\n",
        "X = np.array(X)\n",
        "y = np.array(y,dtype=int)\n",
        "\n",
        "#hot incoder\n",
        "y = to_categorical(y)\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ECSIVmNvanX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalization of data\n",
        "#get mean of index 3 of shape =>3 layers\n",
        "mean_array = np.mean(X, axis=3)\n",
        "print(mean_array.shape)\n",
        "mean_array = np.expand_dims(mean_array, axis=3)\n",
        "print(mean_array.shape)\n",
        "Xnormalized = (X - mean_array)/255.0\n",
        "print(Xnormalized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdK6LXxfR4Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xnormalized.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN5f4AekKTCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "       \n",
        "#spliting training & test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xnormalized,y,test_size=0.2, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epJmYVJ6L73J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_cnn_model1():\n",
        "    model = ml.Sequential()\n",
        "    #32 filters, thier size 3*3\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(100, 100, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',optimizer = tf.train.AdamOptimizer(),metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kE1sGXzcUfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_cnn_model2():\n",
        "    model = ml.Sequential()\n",
        "    #32 filters, thier size 3*3\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(100, 100, 3)))\n",
        "    model.add(layers.AveragePooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.AveragePooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.AveragePooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',optimizer = tf.train.AdamOptimizer(),metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPsaf_z8cUug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_cnn_model3():\n",
        "    model = ml.Sequential()\n",
        "    #32 filters, thier size 3*3\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(100, 100, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',optimizer = tf.train.AdamOptimizer(),metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5CJIYNwcYNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_cnn_model4():\n",
        "    model = ml.Sequential()\n",
        "    #32 filters, thier size 3*3\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(100, 100, 3)))\n",
        "    model.add(layers.AveragePooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.AveragePooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',optimizer = tf.train.AdamOptimizer(),metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRTgjT_CSbVb",
        "colab_type": "code",
        "outputId": "b1e0de17-0496-495e-d2ac-d95fb81a7a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_split = 4\n",
        "val_loss = np.zeros(n_split)\n",
        "val_acc = np.zeros(n_split)\n",
        "\n",
        "k_Fold = KFold(n_splits=4)\n",
        "modeling = [create_cnn_model1,create_cnn_model2,create_cnn_model3,create_cnn_model4]\n",
        "for x in range(4):\n",
        "  i=0\n",
        "  for train, validate in k_Fold.split(X_train, y_train):\n",
        "    model = modeling[x]()\n",
        "    model.fit(X_train[train], y_train[train], epochs=50)\n",
        "    val_loss[i], val_acc[i] = model.evaluate(X_train[validate],y_train[validate])\n",
        "    model.summary()\n",
        "    i+=1\n",
        "  print(\"Average Loss and Accuracy in Architecture\" +str(x+1))\n",
        "  print(val_loss.mean())\n",
        "  print(val_acc.mean()) \n",
        "    #evaluate the testing part\n",
        "  print(\"Evaluate testing part\")\n",
        "  y_test = to_categorical(y_test)\n",
        "  model.evaluate(X_test, y_test)\n",
        "  #get predicted labels\n",
        "  y_predict = model.predict_classes(X_test)\n",
        "  #reverse from categorial \n",
        "  y_test = np.argmax(y_test, axis=1, out=None)\n",
        "  #evaluate model using precision, fscore, & recall\n",
        "  print(classification_report(y_test, y_predict, target_names=Categories))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1236/1236 [==============================] - 6s 5ms/step - loss: 1.6975 - acc: 0.4021\n",
            "Epoch 2/50\n",
            "1236/1236 [==============================] - 0s 374us/step - loss: 0.6964 - acc: 0.7767\n",
            "Epoch 3/50\n",
            "1236/1236 [==============================] - 0s 371us/step - loss: 0.4803 - acc: 0.8463\n",
            "Epoch 4/50\n",
            "1236/1236 [==============================] - 0s 379us/step - loss: 0.3733 - acc: 0.8940\n",
            "Epoch 5/50\n",
            "1236/1236 [==============================] - 0s 364us/step - loss: 0.2619 - acc: 0.9183\n",
            "Epoch 6/50\n",
            "1236/1236 [==============================] - 0s 381us/step - loss: 0.1891 - acc: 0.9458\n",
            "Epoch 7/50\n",
            "1236/1236 [==============================] - 0s 367us/step - loss: 0.1260 - acc: 0.9636\n",
            "Epoch 8/50\n",
            "1236/1236 [==============================] - 0s 393us/step - loss: 0.0800 - acc: 0.9765\n",
            "Epoch 9/50\n",
            "1236/1236 [==============================] - 0s 382us/step - loss: 0.0633 - acc: 0.9806\n",
            "Epoch 10/50\n",
            "1236/1236 [==============================] - 0s 365us/step - loss: 0.0544 - acc: 0.9822\n",
            "Epoch 11/50\n",
            "1236/1236 [==============================] - 0s 383us/step - loss: 0.0304 - acc: 0.9960\n",
            "Epoch 12/50\n",
            "1236/1236 [==============================] - 0s 383us/step - loss: 0.0312 - acc: 0.9960\n",
            "Epoch 13/50\n",
            "1236/1236 [==============================] - 0s 380us/step - loss: 0.0253 - acc: 0.9960\n",
            "Epoch 14/50\n",
            "1236/1236 [==============================] - 0s 381us/step - loss: 0.0467 - acc: 0.9879\n",
            "Epoch 15/50\n",
            "1236/1236 [==============================] - 1s 410us/step - loss: 0.0371 - acc: 0.9927\n",
            "Epoch 16/50\n",
            "1236/1236 [==============================] - 0s 375us/step - loss: 0.0189 - acc: 0.9992\n",
            "Epoch 17/50\n",
            "1236/1236 [==============================] - 0s 401us/step - loss: 0.0150 - acc: 0.9992\n",
            "Epoch 18/50\n",
            "1236/1236 [==============================] - 0s 360us/step - loss: 0.0136 - acc: 0.9992\n",
            "Epoch 19/50\n",
            "1236/1236 [==============================] - 0s 375us/step - loss: 0.0134 - acc: 0.9992\n",
            "Epoch 20/50\n",
            "1236/1236 [==============================] - 0s 364us/step - loss: 0.0134 - acc: 0.9992\n",
            "Epoch 21/50\n",
            "1236/1236 [==============================] - 0s 389us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 22/50\n",
            "1236/1236 [==============================] - 0s 375us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 23/50\n",
            "1236/1236 [==============================] - 0s 379us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 24/50\n",
            "1236/1236 [==============================] - 0s 386us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 25/50\n",
            "1236/1236 [==============================] - 0s 377us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 26/50\n",
            "1236/1236 [==============================] - 0s 393us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 27/50\n",
            "1236/1236 [==============================] - 0s 381us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 28/50\n",
            "1236/1236 [==============================] - 0s 379us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 29/50\n",
            "1236/1236 [==============================] - 0s 382us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 30/50\n",
            "1236/1236 [==============================] - 0s 385us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 31/50\n",
            "1236/1236 [==============================] - 0s 370us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 32/50\n",
            "1236/1236 [==============================] - 0s 388us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 33/50\n",
            "1236/1236 [==============================] - 0s 369us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 34/50\n",
            "1236/1236 [==============================] - 0s 363us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 35/50\n",
            "1236/1236 [==============================] - 0s 382us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 36/50\n",
            "1236/1236 [==============================] - 0s 385us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 37/50\n",
            "1236/1236 [==============================] - 0s 389us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 38/50\n",
            "1236/1236 [==============================] - 0s 364us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 39/50\n",
            "1236/1236 [==============================] - 0s 375us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 40/50\n",
            "1236/1236 [==============================] - 0s 382us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 41/50\n",
            "1236/1236 [==============================] - 0s 386us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 42/50\n",
            "1236/1236 [==============================] - 0s 383us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 43/50\n",
            "1236/1236 [==============================] - 0s 377us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 44/50\n",
            "1236/1236 [==============================] - 0s 402us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 45/50\n",
            "1236/1236 [==============================] - 0s 372us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 46/50\n",
            "1236/1236 [==============================] - 0s 382us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 47/50\n",
            "1236/1236 [==============================] - 0s 373us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 48/50\n",
            "1236/1236 [==============================] - 0s 395us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 49/50\n",
            "1236/1236 [==============================] - 0s 376us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 50/50\n",
            "1236/1236 [==============================] - 0s 375us/step - loss: 0.0131 - acc: 0.9992\n",
            "413/413 [==============================] - 2s 6ms/step\n",
            "Model: \"sequential_112\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_302 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_201 (MaxPoolin (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_303 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_202 (MaxPoolin (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_304 (Conv2D)          (None, 21, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_203 (MaxPoolin (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_112 (Flatten)        (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 10)                128010    \n",
            "=================================================================\n",
            "Total params: 221,258\n",
            "Trainable params: 221,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 6s 5ms/step - loss: 1.6618 - acc: 0.4390\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 0.7550 - acc: 0.7502\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 0.4821 - acc: 0.8391\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 0.3404 - acc: 0.9054\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.2432 - acc: 0.9264\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.1820 - acc: 0.9507\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 368us/step - loss: 0.1370 - acc: 0.9620\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0958 - acc: 0.9741\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0960 - acc: 0.9660\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 0.0780 - acc: 0.9774\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0758 - acc: 0.9782\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0455 - acc: 0.9879\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 387us/step - loss: 0.0625 - acc: 0.9798\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 0.0430 - acc: 0.9887\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 0.0353 - acc: 0.9911\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 362us/step - loss: 0.0348 - acc: 0.9911\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 388us/step - loss: 0.0377 - acc: 0.9943\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 0.0199 - acc: 0.9976\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.0158 - acc: 0.9984\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0138 - acc: 0.9992\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0135 - acc: 0.9992\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 376us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 370us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 362us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 370us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 398us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 377us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 362us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 391us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 365us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 374us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 376us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 376us/step - loss: 0.0131 - acc: 0.9992\n",
            "412/412 [==============================] - 2s 6ms/step\n",
            "Model: \"sequential_113\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_305 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_204 (MaxPoolin (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_306 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_205 (MaxPoolin (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_307 (Conv2D)          (None, 21, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_206 (MaxPoolin (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_113 (Flatten)        (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 10)                128010    \n",
            "=================================================================\n",
            "Total params: 221,258\n",
            "Trainable params: 221,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 6s 5ms/step - loss: 1.7350 - acc: 0.4131\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 376us/step - loss: 0.7809 - acc: 0.7381\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 374us/step - loss: 0.5150 - acc: 0.8496\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 376us/step - loss: 0.3479 - acc: 0.8957\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 365us/step - loss: 0.2706 - acc: 0.9216\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 0.2008 - acc: 0.9369\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 368us/step - loss: 0.1240 - acc: 0.9669\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0976 - acc: 0.9741\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0610 - acc: 0.9871\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 0.0596 - acc: 0.9854\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 0.0634 - acc: 0.9838\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0284 - acc: 0.9968\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 391us/step - loss: 0.0215 - acc: 0.9984\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 387us/step - loss: 0.0175 - acc: 0.9984\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 0.0157 - acc: 0.9984\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 359us/step - loss: 0.0137 - acc: 0.9992\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 387us/step - loss: 0.0135 - acc: 0.9992\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 0.0134 - acc: 0.9992\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0134 - acc: 0.9992\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 376us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 370us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.0132 - acc: 0.9992\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 359us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 374us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 376us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 368us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 395us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 389us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 370us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 377us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 368us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 370us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0131 - acc: 0.9992\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0131 - acc: 0.9992\n",
            "412/412 [==============================] - 2s 6ms/step\n",
            "Model: \"sequential_114\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_308 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_207 (MaxPoolin (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_309 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_208 (MaxPoolin (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_310 (Conv2D)          (None, 21, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_209 (MaxPoolin (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_114 (Flatten)        (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_114 (Dense)            (None, 10)                128010    \n",
            "=================================================================\n",
            "Total params: 221,258\n",
            "Trainable params: 221,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 6s 5ms/step - loss: 1.7519 - acc: 0.4155\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 390us/step - loss: 0.7591 - acc: 0.7478\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.5258 - acc: 0.8343\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 0.3408 - acc: 0.9014\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 380us/step - loss: 0.2496 - acc: 0.9224\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 391us/step - loss: 0.1972 - acc: 0.9353\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 0.1451 - acc: 0.9555\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 0.1107 - acc: 0.9612\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.1022 - acc: 0.9660\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 0.0307 - acc: 0.9895\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 0.0121 - acc: 0.9976\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 370us/step - loss: 0.0114 - acc: 0.9976\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 1s 405us/step - loss: 0.0100 - acc: 0.9960\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 0.0111 - acc: 0.9984\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 399us/step - loss: 0.0177 - acc: 0.9943\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 0.0411 - acc: 0.9895\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 0.0761 - acc: 0.9725\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 365us/step - loss: 0.0299 - acc: 0.9911\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 397us/step - loss: 0.0323 - acc: 0.9919\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 0.0132 - acc: 0.9960\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 370us/step - loss: 0.0040 - acc: 0.9992\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 389us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 392us/step - loss: 5.2889e-04 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 3.4274e-04 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 2.8254e-04 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 401us/step - loss: 2.3475e-04 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 376us/step - loss: 2.0198e-04 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 1.7907e-04 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 1.6155e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 387us/step - loss: 1.4288e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 1.2894e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 1.1781e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 1.0828e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 388us/step - loss: 9.9741e-05 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 9.2076e-05 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 389us/step - loss: 8.5498e-05 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 392us/step - loss: 7.9882e-05 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 374us/step - loss: 7.4108e-05 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 6.9987e-05 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 6.5358e-05 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 376us/step - loss: 6.1584e-05 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 368us/step - loss: 5.7792e-05 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 5.4554e-05 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 392us/step - loss: 5.1495e-05 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 374us/step - loss: 4.8630e-05 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 4.6072e-05 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 380us/step - loss: 4.4143e-05 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 4.1455e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 3.9741e-05 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 388us/step - loss: 3.7688e-05 - acc: 1.0000\n",
            "412/412 [==============================] - 2s 6ms/step\n",
            "Model: \"sequential_115\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_311 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_210 (MaxPoolin (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_312 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_211 (MaxPoolin (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_313 (Conv2D)          (None, 21, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_212 (MaxPoolin (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_115 (Flatten)        (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_115 (Dense)            (None, 10)                128010    \n",
            "=================================================================\n",
            "Total params: 221,258\n",
            "Trainable params: 221,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Average Loss and Accuracy in Architecture1\n",
            "0.6236078811070476\n",
            "0.9163120898294803\n",
            "Evaluate testing part\n",
            "413/413 [==============================] - 0s 223us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97        38\n",
            "           1       0.88      0.98      0.93        45\n",
            "           2       0.95      0.84      0.89        43\n",
            "           3       1.00      0.97      0.99        37\n",
            "           4       0.84      0.95      0.89        43\n",
            "           5       1.00      1.00      1.00        41\n",
            "           6       0.90      0.84      0.87        31\n",
            "           7       0.87      0.89      0.88        44\n",
            "           8       0.89      0.87      0.88        46\n",
            "           9       0.93      0.91      0.92        45\n",
            "\n",
            "    accuracy                           0.92       413\n",
            "   macro avg       0.92      0.92      0.92       413\n",
            "weighted avg       0.92      0.92      0.92       413\n",
            "\n",
            "Epoch 1/50\n",
            "1236/1236 [==============================] - 6s 5ms/step - loss: 1.7907 - acc: 0.3536\n",
            "Epoch 2/50\n",
            "1236/1236 [==============================] - 0s 393us/step - loss: 0.8386 - acc: 0.7265\n",
            "Epoch 3/50\n",
            "1236/1236 [==============================] - 0s 394us/step - loss: 0.5756 - acc: 0.8236\n",
            "Epoch 4/50\n",
            "1236/1236 [==============================] - 0s 402us/step - loss: 0.4348 - acc: 0.8786\n",
            "Epoch 5/50\n",
            "1236/1236 [==============================] - 0s 384us/step - loss: 0.3213 - acc: 0.9045\n",
            "Epoch 6/50\n",
            "1236/1236 [==============================] - 0s 397us/step - loss: 0.2447 - acc: 0.9288\n",
            "Epoch 7/50\n",
            "1236/1236 [==============================] - 0s 388us/step - loss: 0.1688 - acc: 0.9409\n",
            "Epoch 8/50\n",
            "1236/1236 [==============================] - 1s 408us/step - loss: 0.1123 - acc: 0.9636\n",
            "Epoch 9/50\n",
            "1236/1236 [==============================] - 0s 386us/step - loss: 0.0919 - acc: 0.9709\n",
            "Epoch 10/50\n",
            "1236/1236 [==============================] - 1s 405us/step - loss: 0.0887 - acc: 0.9741\n",
            "Epoch 11/50\n",
            "1236/1236 [==============================] - 1s 405us/step - loss: 0.0636 - acc: 0.9822\n",
            "Epoch 12/50\n",
            "1236/1236 [==============================] - 1s 407us/step - loss: 0.0331 - acc: 0.9903\n",
            "Epoch 13/50\n",
            "1236/1236 [==============================] - 0s 398us/step - loss: 0.0297 - acc: 0.9943\n",
            "Epoch 14/50\n",
            "1236/1236 [==============================] - 1s 405us/step - loss: 0.0209 - acc: 0.9951\n",
            "Epoch 15/50\n",
            "1236/1236 [==============================] - 0s 382us/step - loss: 0.0418 - acc: 0.9862\n",
            "Epoch 16/50\n",
            "1236/1236 [==============================] - 0s 393us/step - loss: 0.0269 - acc: 0.9919\n",
            "Epoch 17/50\n",
            "1236/1236 [==============================] - 0s 396us/step - loss: 0.0083 - acc: 0.9984\n",
            "Epoch 18/50\n",
            "1236/1236 [==============================] - 0s 397us/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "1236/1236 [==============================] - 0s 382us/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "1236/1236 [==============================] - 1s 408us/step - loss: 7.0669e-04 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1236/1236 [==============================] - 1s 410us/step - loss: 4.4831e-04 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1236/1236 [==============================] - 0s 398us/step - loss: 3.7948e-04 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1236/1236 [==============================] - 0s 396us/step - loss: 3.2883e-04 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1236/1236 [==============================] - 0s 391us/step - loss: 2.8737e-04 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1236/1236 [==============================] - 0s 393us/step - loss: 2.5528e-04 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1236/1236 [==============================] - 0s 389us/step - loss: 2.3512e-04 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1236/1236 [==============================] - 0s 394us/step - loss: 2.1372e-04 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1236/1236 [==============================] - 0s 392us/step - loss: 1.9280e-04 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1236/1236 [==============================] - 0s 394us/step - loss: 1.7651e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1236/1236 [==============================] - 0s 404us/step - loss: 1.6447e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1236/1236 [==============================] - 0s 384us/step - loss: 1.5224e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1236/1236 [==============================] - 0s 393us/step - loss: 1.4118e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1236/1236 [==============================] - 0s 398us/step - loss: 1.3380e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1236/1236 [==============================] - 1s 411us/step - loss: 1.2443e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1236/1236 [==============================] - 0s 399us/step - loss: 1.1517e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1236/1236 [==============================] - 1s 411us/step - loss: 1.0929e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1236/1236 [==============================] - 0s 393us/step - loss: 1.0167e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1236/1236 [==============================] - 0s 389us/step - loss: 9.6418e-05 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1236/1236 [==============================] - 0s 399us/step - loss: 9.0585e-05 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1236/1236 [==============================] - 0s 396us/step - loss: 8.6678e-05 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1236/1236 [==============================] - 0s 402us/step - loss: 8.2164e-05 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1236/1236 [==============================] - 0s 394us/step - loss: 7.7682e-05 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1236/1236 [==============================] - 0s 389us/step - loss: 7.3459e-05 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1236/1236 [==============================] - 0s 398us/step - loss: 7.0090e-05 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1236/1236 [==============================] - 0s 394us/step - loss: 6.7131e-05 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1236/1236 [==============================] - 0s 397us/step - loss: 6.4051e-05 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1236/1236 [==============================] - 0s 391us/step - loss: 6.0755e-05 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1236/1236 [==============================] - 0s 384us/step - loss: 5.8017e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1236/1236 [==============================] - 0s 384us/step - loss: 5.4932e-05 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1236/1236 [==============================] - 0s 377us/step - loss: 5.2757e-05 - acc: 1.0000\n",
            "413/413 [==============================] - 2s 6ms/step\n",
            "Model: \"sequential_116\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_314 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_102 (Avera (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_315 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_103 (Avera (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_316 (Conv2D)          (None, 21, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_104 (Avera (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_116 (Flatten)        (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_116 (Dense)            (None, 10)                128010    \n",
            "=================================================================\n",
            "Total params: 221,258\n",
            "Trainable params: 221,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 6s 5ms/step - loss: 1.8467 - acc: 0.3622\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 0.8427 - acc: 0.7098\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 0.6031 - acc: 0.8100\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 398us/step - loss: 0.5236 - acc: 0.8335\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 0.4448 - acc: 0.8529\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 374us/step - loss: 0.3516 - acc: 0.8804\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 0.2677 - acc: 0.9232\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 1s 407us/step - loss: 0.2116 - acc: 0.9361\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 0.1393 - acc: 0.9515\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.1634 - acc: 0.9483\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 0.1076 - acc: 0.9693\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 399us/step - loss: 0.0659 - acc: 0.9814\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 0.0459 - acc: 0.9887\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 389us/step - loss: 0.0437 - acc: 0.9903\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 0.0310 - acc: 0.9927\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 0.0264 - acc: 0.9927\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 388us/step - loss: 0.0095 - acc: 0.9992\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.0123 - acc: 0.9976\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 377us/step - loss: 0.0093 - acc: 0.9992\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 395us/step - loss: 0.0078 - acc: 0.9976\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 0.0078 - acc: 0.9960\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.0524 - acc: 0.9806\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 1s 409us/step - loss: 0.0393 - acc: 0.9871\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 392us/step - loss: 0.0501 - acc: 0.9830\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0368 - acc: 0.9895\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0234 - acc: 0.9895\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0050 - acc: 0.9992\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 392us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 1s 413us/step - loss: 5.9775e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 1s 415us/step - loss: 4.3914e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 388us/step - loss: 3.6941e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 399us/step - loss: 3.2112e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 2.8332e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 403us/step - loss: 2.5089e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 2.2765e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 398us/step - loss: 2.0746e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 402us/step - loss: 1.8922e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 1s 409us/step - loss: 1.7248e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 1.5969e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 1.4654e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 391us/step - loss: 1.3611e-04 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 1.2798e-04 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 1.1865e-04 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 1.1056e-04 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 1.0329e-04 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 401us/step - loss: 9.7171e-05 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 389us/step - loss: 9.1021e-05 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 1s 406us/step - loss: 8.5373e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 8.1011e-05 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 7.6101e-05 - acc: 1.0000\n",
            "412/412 [==============================] - 2s 6ms/step\n",
            "Model: \"sequential_117\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_317 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_105 (Avera (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_318 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_106 (Avera (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_319 (Conv2D)          (None, 21, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_107 (Avera (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_117 (Flatten)        (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 10)                128010    \n",
            "=================================================================\n",
            "Total params: 221,258\n",
            "Trainable params: 221,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 6s 5ms/step - loss: 1.9483 - acc: 0.3169\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 1s 416us/step - loss: 0.9389 - acc: 0.7009\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 380us/step - loss: 0.6470 - acc: 0.8011\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.5086 - acc: 0.8488\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 0.3595 - acc: 0.8998\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 387us/step - loss: 0.2733 - acc: 0.9200\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 0.2135 - acc: 0.9313\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 0.1646 - acc: 0.9499\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 398us/step - loss: 0.1402 - acc: 0.9588\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 1s 406us/step - loss: 0.0993 - acc: 0.9725\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 0.0824 - acc: 0.9749\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 0.0437 - acc: 0.9879\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0461 - acc: 0.9879\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 0.0300 - acc: 0.9927\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0475 - acc: 0.9814\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 0.0449 - acc: 0.9863\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 370us/step - loss: 0.0212 - acc: 0.9935\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 400us/step - loss: 0.0180 - acc: 0.9951\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 388us/step - loss: 0.0100 - acc: 0.9976\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 387us/step - loss: 0.0031 - acc: 0.9992\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 388us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 398us/step - loss: 6.6884e-04 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 377us/step - loss: 5.1185e-04 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 4.2009e-04 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 399us/step - loss: 3.6286e-04 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 387us/step - loss: 3.2045e-04 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 2.8543e-04 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 2.5828e-04 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 393us/step - loss: 2.3418e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 2.1268e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 388us/step - loss: 1.9518e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 1.7967e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 1.6851e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 1.5816e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 390us/step - loss: 1.4358e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 1.3379e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 1.2641e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 1.1724e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 1.0992e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 1.0364e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 380us/step - loss: 9.8158e-05 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 1s 406us/step - loss: 9.3016e-05 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 384us/step - loss: 8.7811e-05 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 391us/step - loss: 8.3530e-05 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 399us/step - loss: 7.8988e-05 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 7.5625e-05 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 399us/step - loss: 7.1567e-05 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 390us/step - loss: 6.8734e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 392us/step - loss: 6.5101e-05 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 6.2220e-05 - acc: 1.0000\n",
            "412/412 [==============================] - 2s 6ms/step\n",
            "Model: \"sequential_118\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_320 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_108 (Avera (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_321 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_109 (Avera (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_322 (Conv2D)          (None, 21, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_110 (Avera (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_118 (Flatten)        (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 10)                128010    \n",
            "=================================================================\n",
            "Total params: 221,258\n",
            "Trainable params: 221,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 6s 5ms/step - loss: 1.9072 - acc: 0.3630\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.9245 - acc: 0.6928\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 400us/step - loss: 0.6726 - acc: 0.7801\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 370us/step - loss: 0.5281 - acc: 0.8310\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 380us/step - loss: 0.4341 - acc: 0.8626\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.3005 - acc: 0.9078\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 0.2063 - acc: 0.9386\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.1521 - acc: 0.9499\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.1111 - acc: 0.9644\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.1018 - acc: 0.9669\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0916 - acc: 0.9774\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0465 - acc: 0.9887\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0469 - acc: 0.9830\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 392us/step - loss: 0.0390 - acc: 0.9887\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 0.0314 - acc: 0.9927\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 0.0099 - acc: 0.9984\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 7.8090e-04 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 390us/step - loss: 6.3448e-04 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 387us/step - loss: 5.3723e-04 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 1s 405us/step - loss: 4.7757e-04 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 389us/step - loss: 4.2763e-04 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 391us/step - loss: 3.8000e-04 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 3.5418e-04 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 3.0059e-04 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 2.8370e-04 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 390us/step - loss: 2.6047e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 389us/step - loss: 2.3838e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 2.1276e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 403us/step - loss: 2.0111e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 391us/step - loss: 1.8470e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 389us/step - loss: 1.7433e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 383us/step - loss: 1.5924e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 1s 406us/step - loss: 1.4907e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 1.3227e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 391us/step - loss: 1.1525e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 377us/step - loss: 1.0328e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 397us/step - loss: 9.3060e-05 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 390us/step - loss: 8.1397e-05 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 1s 404us/step - loss: 7.2947e-05 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 394us/step - loss: 6.5175e-05 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 398us/step - loss: 5.7728e-05 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 5.3361e-05 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 1s 405us/step - loss: 5.2918e-05 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 4.6441e-05 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 395us/step - loss: 4.0592e-05 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 374us/step - loss: 3.6229e-05 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 389us/step - loss: 3.3898e-05 - acc: 1.0000\n",
            "412/412 [==============================] - 3s 6ms/step\n",
            "Model: \"sequential_119\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_323 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_111 (Avera (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_324 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_112 (Avera (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_325 (Conv2D)          (None, 21, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_113 (Avera (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_119 (Flatten)        (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_119 (Dense)            (None, 10)                128010    \n",
            "=================================================================\n",
            "Total params: 221,258\n",
            "Trainable params: 221,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Average Loss and Accuracy in Architecture2\n",
            "0.8162149060919074\n",
            "0.9060009644351497\n",
            "Evaluate testing part\n",
            "413/413 [==============================] - 0s 231us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96        38\n",
            "           1       0.88      1.00      0.94        45\n",
            "           2       0.94      0.79      0.86        43\n",
            "           3       1.00      0.89      0.94        37\n",
            "           4       0.89      0.91      0.90        43\n",
            "           5       1.00      0.98      0.99        41\n",
            "           6       0.83      0.94      0.88        31\n",
            "           7       0.83      0.91      0.87        44\n",
            "           8       0.86      0.83      0.84        46\n",
            "           9       0.91      0.91      0.91        45\n",
            "\n",
            "    accuracy                           0.91       413\n",
            "   macro avg       0.91      0.91      0.91       413\n",
            "weighted avg       0.91      0.91      0.91       413\n",
            "\n",
            "Epoch 1/50\n",
            "1236/1236 [==============================] - 6s 5ms/step - loss: 1.6611 - acc: 0.4515\n",
            "Epoch 2/50\n",
            "1236/1236 [==============================] - 0s 353us/step - loss: 0.7649 - acc: 0.7589\n",
            "Epoch 3/50\n",
            "1236/1236 [==============================] - 0s 337us/step - loss: 0.6198 - acc: 0.8042\n",
            "Epoch 4/50\n",
            "1236/1236 [==============================] - 0s 351us/step - loss: 0.5071 - acc: 0.8333\n",
            "Epoch 5/50\n",
            "1236/1236 [==============================] - 0s 351us/step - loss: 0.4252 - acc: 0.8681\n",
            "Epoch 6/50\n",
            "1236/1236 [==============================] - 0s 356us/step - loss: 0.3727 - acc: 0.8827\n",
            "Epoch 7/50\n",
            "1236/1236 [==============================] - 0s 353us/step - loss: 0.3191 - acc: 0.8883\n",
            "Epoch 8/50\n",
            "1236/1236 [==============================] - 0s 341us/step - loss: 0.2494 - acc: 0.9223\n",
            "Epoch 9/50\n",
            "1236/1236 [==============================] - 0s 340us/step - loss: 0.2184 - acc: 0.9264\n",
            "Epoch 10/50\n",
            "1236/1236 [==============================] - 0s 355us/step - loss: 0.1660 - acc: 0.9539\n",
            "Epoch 11/50\n",
            "1236/1236 [==============================] - 0s 349us/step - loss: 0.1205 - acc: 0.9757\n",
            "Epoch 12/50\n",
            "1236/1236 [==============================] - 0s 349us/step - loss: 0.1024 - acc: 0.9733\n",
            "Epoch 13/50\n",
            "1236/1236 [==============================] - 0s 347us/step - loss: 0.0809 - acc: 0.9822\n",
            "Epoch 14/50\n",
            "1236/1236 [==============================] - 0s 353us/step - loss: 0.0658 - acc: 0.9846\n",
            "Epoch 15/50\n",
            "1236/1236 [==============================] - 0s 342us/step - loss: 0.0524 - acc: 0.9887\n",
            "Epoch 16/50\n",
            "1236/1236 [==============================] - 0s 349us/step - loss: 0.0433 - acc: 0.9927\n",
            "Epoch 17/50\n",
            "1236/1236 [==============================] - 0s 352us/step - loss: 0.0301 - acc: 0.9960\n",
            "Epoch 18/50\n",
            "1236/1236 [==============================] - 0s 332us/step - loss: 0.0202 - acc: 0.9992\n",
            "Epoch 19/50\n",
            "1236/1236 [==============================] - 0s 349us/step - loss: 0.0175 - acc: 0.9992\n",
            "Epoch 20/50\n",
            "1236/1236 [==============================] - 0s 339us/step - loss: 0.0162 - acc: 0.9992\n",
            "Epoch 21/50\n",
            "1236/1236 [==============================] - 0s 338us/step - loss: 0.0157 - acc: 0.9992\n",
            "Epoch 22/50\n",
            "1236/1236 [==============================] - 0s 339us/step - loss: 0.0153 - acc: 0.9992\n",
            "Epoch 23/50\n",
            "1236/1236 [==============================] - 0s 336us/step - loss: 0.0150 - acc: 0.9992\n",
            "Epoch 24/50\n",
            "1236/1236 [==============================] - 0s 355us/step - loss: 0.0147 - acc: 0.9992\n",
            "Epoch 25/50\n",
            "1236/1236 [==============================] - 0s 350us/step - loss: 0.0145 - acc: 0.9992\n",
            "Epoch 26/50\n",
            "1236/1236 [==============================] - 0s 368us/step - loss: 0.0143 - acc: 0.9992\n",
            "Epoch 27/50\n",
            "1236/1236 [==============================] - 0s 335us/step - loss: 0.0142 - acc: 0.9992\n",
            "Epoch 28/50\n",
            "1236/1236 [==============================] - 0s 330us/step - loss: 0.0141 - acc: 0.9992\n",
            "Epoch 29/50\n",
            "1236/1236 [==============================] - 0s 352us/step - loss: 0.0140 - acc: 0.9992\n",
            "Epoch 30/50\n",
            "1236/1236 [==============================] - 0s 335us/step - loss: 0.0140 - acc: 0.9992\n",
            "Epoch 31/50\n",
            "1236/1236 [==============================] - 0s 352us/step - loss: 0.0138 - acc: 0.9992\n",
            "Epoch 32/50\n",
            "1236/1236 [==============================] - 0s 359us/step - loss: 0.0138 - acc: 0.9992\n",
            "Epoch 33/50\n",
            "1236/1236 [==============================] - 0s 337us/step - loss: 0.0137 - acc: 0.9992\n",
            "Epoch 34/50\n",
            "1236/1236 [==============================] - 0s 351us/step - loss: 0.0136 - acc: 0.9992\n",
            "Epoch 35/50\n",
            "1236/1236 [==============================] - 0s 338us/step - loss: 0.0136 - acc: 0.9992\n",
            "Epoch 36/50\n",
            "1236/1236 [==============================] - 0s 358us/step - loss: 0.0136 - acc: 0.9992\n",
            "Epoch 37/50\n",
            "1236/1236 [==============================] - 0s 356us/step - loss: 0.0135 - acc: 0.9992\n",
            "Epoch 38/50\n",
            "1236/1236 [==============================] - 0s 356us/step - loss: 0.0135 - acc: 0.9992\n",
            "Epoch 39/50\n",
            "1236/1236 [==============================] - 0s 359us/step - loss: 0.0135 - acc: 0.9992\n",
            "Epoch 40/50\n",
            "1236/1236 [==============================] - 0s 364us/step - loss: 0.0134 - acc: 0.9992\n",
            "Epoch 41/50\n",
            "1236/1236 [==============================] - 0s 386us/step - loss: 0.0134 - acc: 0.9992\n",
            "Epoch 42/50\n",
            "1236/1236 [==============================] - 0s 355us/step - loss: 0.0134 - acc: 0.9992\n",
            "Epoch 43/50\n",
            "1236/1236 [==============================] - 0s 354us/step - loss: 0.0134 - acc: 0.9992\n",
            "Epoch 44/50\n",
            "1236/1236 [==============================] - 0s 339us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 45/50\n",
            "1236/1236 [==============================] - 0s 364us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 46/50\n",
            "1236/1236 [==============================] - 0s 346us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 47/50\n",
            "1236/1236 [==============================] - 0s 343us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 48/50\n",
            "1236/1236 [==============================] - 0s 350us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 49/50\n",
            "1236/1236 [==============================] - 0s 347us/step - loss: 0.0133 - acc: 0.9992\n",
            "Epoch 50/50\n",
            "1236/1236 [==============================] - 0s 343us/step - loss: 0.0133 - acc: 0.9992\n",
            "413/413 [==============================] - 3s 6ms/step\n",
            "Model: \"sequential_120\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_326 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_213 (MaxPoolin (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_327 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_214 (MaxPoolin (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_120 (Flatten)        (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense_120 (Dense)            (None, 10)                338570    \n",
            "=================================================================\n",
            "Total params: 357,962\n",
            "Trainable params: 357,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 6s 5ms/step - loss: 1.6818 - acc: 0.4163\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 0.7540 - acc: 0.7502\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 368us/step - loss: 0.6267 - acc: 0.7947\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 335us/step - loss: 0.4939 - acc: 0.8399\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 0.3839 - acc: 0.8836\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 0.2985 - acc: 0.9119\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 340us/step - loss: 0.2484 - acc: 0.9264\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 342us/step - loss: 0.1805 - acc: 0.9507\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 341us/step - loss: 0.1981 - acc: 0.9305\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 0.1236 - acc: 0.9652\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 330us/step - loss: 0.0923 - acc: 0.9741\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 347us/step - loss: 0.1062 - acc: 0.9685\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 0.0534 - acc: 0.9871\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 353us/step - loss: 0.0249 - acc: 0.9984\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 0.0174 - acc: 0.9968\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0116 - acc: 0.9992\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 366us/step - loss: 0.0100 - acc: 0.9992\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 343us/step - loss: 0.0125 - acc: 0.9960\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 359us/step - loss: 0.0075 - acc: 0.9992\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 359us/step - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 341us/step - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 351us/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 360us/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 359us/step - loss: 9.1779e-04 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 337us/step - loss: 8.5203e-04 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 7.4774e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 6.9817e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 365us/step - loss: 6.4939e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 6.0307e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 377us/step - loss: 5.6949e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 390us/step - loss: 4.9934e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 4.9612e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 347us/step - loss: 4.7415e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 4.3128e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 358us/step - loss: 3.9043e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 3.6518e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 347us/step - loss: 3.4351e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 3.2585e-04 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 336us/step - loss: 3.0634e-04 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 2.9554e-04 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 2.7328e-04 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 2.6682e-04 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 2.5040e-04 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 339us/step - loss: 2.3258e-04 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 347us/step - loss: 2.2373e-04 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 340us/step - loss: 2.1681e-04 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 2.1031e-04 - acc: 1.0000\n",
            "412/412 [==============================] - 3s 6ms/step\n",
            "Model: \"sequential_121\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_328 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_215 (MaxPoolin (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_329 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_216 (MaxPoolin (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_121 (Flatten)        (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense_121 (Dense)            (None, 10)                338570    \n",
            "=================================================================\n",
            "Total params: 357,962\n",
            "Trainable params: 357,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 7s 5ms/step - loss: 1.7486 - acc: 0.3622\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 347us/step - loss: 0.8922 - acc: 0.6960\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 341us/step - loss: 0.6671 - acc: 0.7995\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 341us/step - loss: 0.5582 - acc: 0.8351\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.4682 - acc: 0.8569\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 340us/step - loss: 0.4186 - acc: 0.8674\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 363us/step - loss: 0.3118 - acc: 0.9062\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 0.2235 - acc: 0.9329\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 0.1954 - acc: 0.9450\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 0.1433 - acc: 0.9636\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 359us/step - loss: 0.0988 - acc: 0.9774\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 0.0782 - acc: 0.9814\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 348us/step - loss: 0.0485 - acc: 0.9927\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 0.0292 - acc: 0.9943\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 333us/step - loss: 0.0244 - acc: 0.9960\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 0.0197 - acc: 0.9968\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 0.0109 - acc: 0.9984\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 344us/step - loss: 0.0059 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 337us/step - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 363us/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 351us/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 339us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 342us/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 9.1791e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 345us/step - loss: 8.0060e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 344us/step - loss: 7.7086e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 336us/step - loss: 7.4203e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 6.5783e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 344us/step - loss: 6.5065e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 344us/step - loss: 5.5344e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 5.2142e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 5.1501e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 4.7305e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 4.2755e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 3.9293e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 3.8622e-04 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 3.5567e-04 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 3.3352e-04 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 345us/step - loss: 3.1472e-04 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 345us/step - loss: 3.0411e-04 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 3.0195e-04 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 351us/step - loss: 2.7076e-04 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 347us/step - loss: 2.5871e-04 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 2.4553e-04 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 2.3014e-04 - acc: 1.0000\n",
            "412/412 [==============================] - 3s 6ms/step\n",
            "Model: \"sequential_122\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_330 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_217 (MaxPoolin (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_331 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_218 (MaxPoolin (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_122 (Flatten)        (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense_122 (Dense)            (None, 10)                338570    \n",
            "=================================================================\n",
            "Total params: 357,962\n",
            "Trainable params: 357,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 7s 5ms/step - loss: 1.6971 - acc: 0.4196\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 348us/step - loss: 0.7985 - acc: 0.7413\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 345us/step - loss: 0.5964 - acc: 0.8076\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 339us/step - loss: 0.5018 - acc: 0.8399\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 344us/step - loss: 0.3507 - acc: 0.8933\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 0.2557 - acc: 0.9256\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 347us/step - loss: 0.1993 - acc: 0.9353\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 0.1409 - acc: 0.9596\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 337us/step - loss: 0.0880 - acc: 0.9741\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 341us/step - loss: 0.0531 - acc: 0.9895\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 340us/step - loss: 0.0676 - acc: 0.9790\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 0.0600 - acc: 0.9846\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 337us/step - loss: 0.0258 - acc: 0.9951\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 0.0218 - acc: 0.9951\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 344us/step - loss: 0.0104 - acc: 0.9984\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 332us/step - loss: 0.0049 - acc: 1.0000\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 345us/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 342us/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 351us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 353us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 338us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 9.7510e-04 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 353us/step - loss: 8.7136e-04 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 342us/step - loss: 8.1614e-04 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 351us/step - loss: 7.2924e-04 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 6.7724e-04 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 348us/step - loss: 6.0975e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 6.0629e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 5.3354e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 334us/step - loss: 4.9335e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 345us/step - loss: 4.6623e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 363us/step - loss: 4.2449e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 347us/step - loss: 4.1382e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 3.8530e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 3.6185e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 343us/step - loss: 3.3980e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 340us/step - loss: 3.1869e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 2.9961e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 337us/step - loss: 2.9807e-04 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 2.6622e-04 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 2.4952e-04 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 333us/step - loss: 2.4142e-04 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 2.2862e-04 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 339us/step - loss: 2.1649e-04 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 2.0737e-04 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 1.9614e-04 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 344us/step - loss: 1.8423e-04 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 1.7660e-04 - acc: 1.0000\n",
            "412/412 [==============================] - 3s 6ms/step\n",
            "Model: \"sequential_123\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_332 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_219 (MaxPoolin (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_333 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_220 (MaxPoolin (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_123 (Flatten)        (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense_123 (Dense)            (None, 10)                338570    \n",
            "=================================================================\n",
            "Total params: 357,962\n",
            "Trainable params: 357,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Average Loss and Accuracy in Architecture3\n",
            "1.0319100151131382\n",
            "0.8587075973733915\n",
            "Evaluate testing part\n",
            "413/413 [==============================] - 0s 258us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96        38\n",
            "           1       0.82      0.93      0.87        45\n",
            "           2       0.74      0.67      0.71        43\n",
            "           3       0.95      0.97      0.96        37\n",
            "           4       0.65      0.79      0.72        43\n",
            "           5       1.00      0.93      0.96        41\n",
            "           6       0.70      0.68      0.69        31\n",
            "           7       0.80      0.84      0.82        44\n",
            "           8       0.85      0.72      0.78        46\n",
            "           9       0.93      0.89      0.91        45\n",
            "\n",
            "    accuracy                           0.84       413\n",
            "   macro avg       0.84      0.84      0.84       413\n",
            "weighted avg       0.84      0.84      0.84       413\n",
            "\n",
            "Epoch 1/50\n",
            "1236/1236 [==============================] - 6s 5ms/step - loss: 1.7303 - acc: 0.4037\n",
            "Epoch 2/50\n",
            "1236/1236 [==============================] - 0s 346us/step - loss: 0.7976 - acc: 0.7411\n",
            "Epoch 3/50\n",
            "1236/1236 [==============================] - 0s 369us/step - loss: 0.6207 - acc: 0.8083\n",
            "Epoch 4/50\n",
            "1236/1236 [==============================] - 0s 341us/step - loss: 0.5044 - acc: 0.8382\n",
            "Epoch 5/50\n",
            "1236/1236 [==============================] - 0s 364us/step - loss: 0.4240 - acc: 0.8689\n",
            "Epoch 6/50\n",
            "1236/1236 [==============================] - 0s 393us/step - loss: 0.4025 - acc: 0.8608\n",
            "Epoch 7/50\n",
            "1236/1236 [==============================] - 0s 354us/step - loss: 0.3361 - acc: 0.8924\n",
            "Epoch 8/50\n",
            "1236/1236 [==============================] - 0s 361us/step - loss: 0.2641 - acc: 0.9207\n",
            "Epoch 9/50\n",
            "1236/1236 [==============================] - 0s 344us/step - loss: 0.2210 - acc: 0.9337\n",
            "Epoch 10/50\n",
            "1236/1236 [==============================] - 0s 377us/step - loss: 0.1277 - acc: 0.9684\n",
            "Epoch 11/50\n",
            "1236/1236 [==============================] - 1s 454us/step - loss: 0.1202 - acc: 0.9628\n",
            "Epoch 12/50\n",
            "1236/1236 [==============================] - 0s 361us/step - loss: 0.0974 - acc: 0.9741\n",
            "Epoch 13/50\n",
            "1236/1236 [==============================] - 0s 342us/step - loss: 0.0567 - acc: 0.9919\n",
            "Epoch 14/50\n",
            "1236/1236 [==============================] - 0s 360us/step - loss: 0.0373 - acc: 0.9927\n",
            "Epoch 15/50\n",
            "1236/1236 [==============================] - 0s 357us/step - loss: 0.0559 - acc: 0.9830\n",
            "Epoch 16/50\n",
            "1236/1236 [==============================] - 0s 386us/step - loss: 0.0394 - acc: 0.9903\n",
            "Epoch 17/50\n",
            "1236/1236 [==============================] - 0s 368us/step - loss: 0.0360 - acc: 0.9895\n",
            "Epoch 18/50\n",
            "1236/1236 [==============================] - 0s 349us/step - loss: 0.0224 - acc: 0.9951\n",
            "Epoch 19/50\n",
            "1236/1236 [==============================] - 0s 387us/step - loss: 0.0092 - acc: 0.9992\n",
            "Epoch 20/50\n",
            "1236/1236 [==============================] - 0s 355us/step - loss: 0.0042 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1236/1236 [==============================] - 0s 374us/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1236/1236 [==============================] - 0s 347us/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1236/1236 [==============================] - 0s 363us/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1236/1236 [==============================] - 0s 387us/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1236/1236 [==============================] - 0s 376us/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1236/1236 [==============================] - 0s 384us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1236/1236 [==============================] - 0s 368us/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1236/1236 [==============================] - 0s 361us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1236/1236 [==============================] - 0s 332us/step - loss: 9.9595e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1236/1236 [==============================] - 0s 387us/step - loss: 9.0209e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1236/1236 [==============================] - 0s 378us/step - loss: 8.0335e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1236/1236 [==============================] - 0s 375us/step - loss: 7.4835e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1236/1236 [==============================] - 0s 365us/step - loss: 7.0641e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1236/1236 [==============================] - 0s 338us/step - loss: 6.5671e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1236/1236 [==============================] - 0s 358us/step - loss: 5.9560e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1236/1236 [==============================] - 0s 348us/step - loss: 5.4603e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1236/1236 [==============================] - 0s 352us/step - loss: 5.0644e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1236/1236 [==============================] - 0s 354us/step - loss: 4.8004e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1236/1236 [==============================] - 0s 354us/step - loss: 4.5741e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1236/1236 [==============================] - 0s 354us/step - loss: 4.3135e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1236/1236 [==============================] - 0s 343us/step - loss: 4.0423e-04 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1236/1236 [==============================] - 0s 349us/step - loss: 3.7420e-04 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1236/1236 [==============================] - 0s 355us/step - loss: 3.5809e-04 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1236/1236 [==============================] - 0s 356us/step - loss: 3.3488e-04 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1236/1236 [==============================] - 0s 364us/step - loss: 3.1496e-04 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1236/1236 [==============================] - 0s 386us/step - loss: 2.9841e-04 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1236/1236 [==============================] - 0s 372us/step - loss: 2.8198e-04 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1236/1236 [==============================] - 0s 351us/step - loss: 2.6856e-04 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1236/1236 [==============================] - 0s 391us/step - loss: 2.5278e-04 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1236/1236 [==============================] - 0s 373us/step - loss: 2.3867e-04 - acc: 1.0000\n",
            "413/413 [==============================] - 3s 6ms/step\n",
            "Model: \"sequential_124\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_334 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_114 (Avera (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_335 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_115 (Avera (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_124 (Flatten)        (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 10)                338570    \n",
            "=================================================================\n",
            "Total params: 357,962\n",
            "Trainable params: 357,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 7s 6ms/step - loss: 1.7248 - acc: 0.4074\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 0.8252 - acc: 0.7171\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 390us/step - loss: 0.6144 - acc: 0.8068\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 0.5457 - acc: 0.8173\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 0.4665 - acc: 0.8480\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 362us/step - loss: 0.3767 - acc: 0.8795\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 358us/step - loss: 0.3404 - acc: 0.8844\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 363us/step - loss: 0.2934 - acc: 0.9070\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 0.2334 - acc: 0.9281\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 0.1430 - acc: 0.9652\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 0.1162 - acc: 0.9644\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 0.0988 - acc: 0.9741\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 364us/step - loss: 0.0659 - acc: 0.9790\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 0.0543 - acc: 0.9895\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 0.0349 - acc: 0.9903\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0341 - acc: 0.9903\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 363us/step - loss: 0.0317 - acc: 0.9927\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.0192 - acc: 0.9951\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 360us/step - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 380us/step - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 366us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 379us/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 374us/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 386us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 9.1888e-04 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 364us/step - loss: 8.4686e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 7.8044e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 7.1720e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 365us/step - loss: 6.4109e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 5.8734e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 5.4460e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 374us/step - loss: 5.1297e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 359us/step - loss: 4.5199e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 366us/step - loss: 4.2881e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 363us/step - loss: 3.8630e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 3.5932e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 3.1281e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 2.7411e-04 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 2.4565e-04 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 362us/step - loss: 2.1771e-04 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 1.8708e-04 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 1.7149e-04 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 1.4564e-04 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 387us/step - loss: 1.2846e-04 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 368us/step - loss: 1.1298e-04 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 1.0038e-04 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 382us/step - loss: 8.8314e-05 - acc: 1.0000\n",
            "412/412 [==============================] - 3s 7ms/step\n",
            "Model: \"sequential_125\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_336 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_116 (Avera (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_337 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_117 (Avera (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_125 (Flatten)        (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 10)                338570    \n",
            "=================================================================\n",
            "Total params: 357,962\n",
            "Trainable params: 357,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 7s 5ms/step - loss: 1.8077 - acc: 0.3751\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.9126 - acc: 0.7106\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 363us/step - loss: 0.7327 - acc: 0.7777\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 358us/step - loss: 0.6010 - acc: 0.8165\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 351us/step - loss: 0.5200 - acc: 0.8416\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 0.4165 - acc: 0.8747\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 0.3170 - acc: 0.9030\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 359us/step - loss: 0.2777 - acc: 0.9143\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 358us/step - loss: 0.1955 - acc: 0.9475\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 0.1342 - acc: 0.9660\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 0.1035 - acc: 0.9766\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 0.0808 - acc: 0.9806\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 360us/step - loss: 0.0660 - acc: 0.9854\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 341us/step - loss: 0.0546 - acc: 0.9822\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 345us/step - loss: 0.0607 - acc: 0.9798\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 366us/step - loss: 0.0220 - acc: 0.9960\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0191 - acc: 0.9976\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 365us/step - loss: 0.0124 - acc: 0.9984\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 0.0066 - acc: 0.9992\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 0.0076 - acc: 0.9992\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 346us/step - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 377us/step - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 0.0021 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 342us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 368us/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 345us/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 352us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 9.4201e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 340us/step - loss: 8.9601e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 362us/step - loss: 8.3057e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 358us/step - loss: 7.1984e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 348us/step - loss: 6.7480e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 6.1177e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 5.8252e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 362us/step - loss: 5.6663e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 360us/step - loss: 5.1557e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 4.8299e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 348us/step - loss: 4.3894e-04 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 353us/step - loss: 4.3487e-04 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 4.0381e-04 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 3.7355e-04 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 3.5643e-04 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 360us/step - loss: 3.2943e-04 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 3.1842e-04 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 351us/step - loss: 3.1128e-04 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 349us/step - loss: 2.8400e-04 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 353us/step - loss: 2.6462e-04 - acc: 1.0000\n",
            "412/412 [==============================] - 3s 6ms/step\n",
            "Model: \"sequential_126\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_338 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_118 (Avera (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_339 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_119 (Avera (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_126 (Flatten)        (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense_126 (Dense)            (None, 10)                338570    \n",
            "=================================================================\n",
            "Total params: 357,962\n",
            "Trainable params: 357,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 7s 5ms/step - loss: 1.9310 - acc: 0.3112\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 0.8757 - acc: 0.7090\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 0.6379 - acc: 0.8003\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 0.5482 - acc: 0.8181\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 366us/step - loss: 0.4820 - acc: 0.8399\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 396us/step - loss: 0.4049 - acc: 0.8755\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 353us/step - loss: 0.3302 - acc: 0.8909\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 0.2494 - acc: 0.9297\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 0.2076 - acc: 0.9450\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 0.1821 - acc: 0.9418\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 0.1076 - acc: 0.9757\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 0.0852 - acc: 0.9830\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 371us/step - loss: 0.0478 - acc: 0.9879\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 381us/step - loss: 0.0449 - acc: 0.9903\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 0.0316 - acc: 0.9919\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0181 - acc: 0.9976\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 353us/step - loss: 0.0253 - acc: 0.9968\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 375us/step - loss: 0.0178 - acc: 0.9976\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 369us/step - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 378us/step - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 358us/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 364us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 385us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 373us/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 365us/step - loss: 9.5794e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 357us/step - loss: 8.4499e-04 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 364us/step - loss: 7.8660e-04 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 367us/step - loss: 7.2780e-04 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 359us/step - loss: 6.7597e-04 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 6.4392e-04 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 5.6678e-04 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 362us/step - loss: 5.2371e-04 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 356us/step - loss: 4.9022e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 4.5306e-04 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 360us/step - loss: 4.3152e-04 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 361us/step - loss: 3.9350e-04 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 350us/step - loss: 3.6559e-04 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 360us/step - loss: 3.3426e-04 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 3.2129e-04 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 354us/step - loss: 3.0755e-04 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 355us/step - loss: 2.8684e-04 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 364us/step - loss: 2.6125e-04 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 372us/step - loss: 2.4999e-04 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 366us/step - loss: 2.4788e-04 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 366us/step - loss: 2.3347e-04 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 351us/step - loss: 2.1660e-04 - acc: 1.0000\n",
            "412/412 [==============================] - 3s 6ms/step\n",
            "Model: \"sequential_127\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_340 (Conv2D)          (None, 98, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_120 (Avera (None, 49, 49, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_341 (Conv2D)          (None, 47, 47, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_121 (Avera (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_127 (Flatten)        (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 10)                338570    \n",
            "=================================================================\n",
            "Total params: 357,962\n",
            "Trainable params: 357,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Average Loss and Accuracy in Architecture4\n",
            "1.1696190949863152\n",
            "0.8435376947501132\n",
            "Evaluate testing part\n",
            "413/413 [==============================] - 0s 247us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95        38\n",
            "           1       0.84      0.96      0.90        45\n",
            "           2       0.78      0.67      0.72        43\n",
            "           3       0.94      0.89      0.92        37\n",
            "           4       0.65      0.79      0.72        43\n",
            "           5       0.97      0.90      0.94        41\n",
            "           6       0.69      0.71      0.70        31\n",
            "           7       0.77      0.84      0.80        44\n",
            "           8       0.86      0.70      0.77        46\n",
            "           9       0.95      0.91      0.93        45\n",
            "\n",
            "    accuracy                           0.84       413\n",
            "   macro avg       0.84      0.83      0.83       413\n",
            "weighted avg       0.84      0.84      0.84       413\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_2xqQgwIX70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FVBQPzmJgCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUoCtD5-KrSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}